---
layout: page  
title: Distributed and Lightweight Machine Learning on Clusters  
description:  
img: /assets/img/distributed_ml.jpg  
importance: 1  
category: Academic Projects
subcategory: Capstone
related_publications:  

---

## ğŸ› ï¸ **Techstack Used**  

- **Distributed Computing**: Apache Hadoop, Spark, Flink  
- **Machine Learning Libraries**: PySpark, MLlib  
- **Clustering Techniques**: K-means, K-medoids, CLARA  
- **Data Querying and Analysis**: Apache Hive  
- **Hardware**: 120-node cluster, Raspberry Pi  
- **Development and Version Control Tools**: Git, GitHub  

---

## ğŸ“– **Introduction**  

- **Optimized ML for Distributed Systems**: Designed scalable clustering models using K-means, K-medoids, and CLARA.  
- **Resource-Constrained ML**: Deployed ML solutions on Raspberry Pi, reducing development time by 25%.  

## ğŸ“Š **Dataset**  

- **Large-Scale Data Processing**: Efficiently handled 10M+ records across distributed clusters.  
- **Optimized Querying**: Integrated Apache Hive for enhanced data analysis.  

## ğŸ” **Methodology**  

- **Cluster Deployment**: Redesigned and optimized Hadoop, Spark, and Flink on a 120-node infrastructure.  
- **Scalable ML Workflows**: Implemented efficient clustering models for predictive analytics.  

## ğŸ“ˆ **Results**  

- **Performance Boost**: Achieved significant reductions in processing time and computational overhead.  
- **Scalability**: Enabled robust data analysis on both high-performance clusters and edge devices.  
- **Research Contribution**: Authored a thesis on distributed ML performance across various environments.  

[//]: # (## ğŸ–¼ï¸ **Visualizations**  )

[//]: # ()
[//]: # (_Visual representations of the project:_  )

[//]: # ()
[//]: # (![Distributed ML Processing]&#40;/assets/img/distributed_ml_visual.jpeg&#41;  )

[//]: # ()
[//]: # (---)
