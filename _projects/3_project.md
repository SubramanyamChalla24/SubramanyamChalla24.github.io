---
layout: page
title: Novel Object Detection in Autonomous Vehicles using Reasoning by Elimination
description:
img: /assets/img/object_detection.jpg
redirect:
importance: 3
category: Course Projects
---

# Autonomous Vehicle Object Detection Using Reinforcement Learning

## ğŸ› ï¸ Tech Stack Used

- **Core Programming Language**: Python
- **Machine Learning Frameworks**: PyTorch, Reinforcement Learning, Proximal Policy Optimization (PPO)

---

## ğŸ“– Introduction

- **Concept**: Developing an innovative object detection system for autonomous vehicles using a reasoning by elimination approach.
- **Objective**: Enhance the reliability and efficiency of autonomous vehicle perception systems in various environments.

## ğŸ“Š Dataset

- **Icon Image Dataset (Nounproject)**: Custom dataset of 6000 images in 20 classes with 6 color variations, using icons from â€˜The Noun Projectâ€™.
- **Real World Image Dataset**: Generated using Stable Diffusion XL base-1.0 with HuggingFace, focusing on 7 classes colored in 6 different shades, totaling 1260 images.
- **Test Dataset**: Includes unseen classes and colors to evaluate the model's adaptability.
- **Dataset Quality Assessment**: Employed 'Everypixel' API for aesthetic scoring and quality assurance.

## ğŸ” Methodology

- Worked as a group on this project
- **Perception Model Development**: Used ResNet and BERT frameworks to train perception module .
- Embeds an objectâ€™s visual appearance along with its textual description in a single multi-modal space. By using symmetric contrastive loss, the two mappings are learned by maximising the cosine-similarity between the visual and textual feature vectors.
- **Custom Dataset Creation**: Generated 2000 images using Stable Diffusion SDXL, specifically focusing on cars and other road objects.
- **Reasoning Model with PPO**: Developed a custom policy network with Proximal Policy Optimization for efficient object identification.

## ğŸ“ˆ Results

### Reasoning Module Performance

- **Seen and Unseen Object Recognition**:
  - The RL agent demonstrated notable efficiency in identifying both seen and unseen objects.
  - **Seen Accuracy**: Achieved 92% (Â±1.26) on the Nounproject dataset, outperforming the baseline of 88% (Â±3.24).
  - **Unseen Accuracy**: Comparable results with 65% (Â±3.15) against the baseline's 67% (Â±4.72).

### Comparative Analysis

- **Nounproject Dataset**:

  - Our approach showed superior performance on seen objects and comparable results on unseen objects.

- **Real World Dataset**:
  - **Seen Accuracy**: Recorded at 86% (Â±1.24), demonstrating robustness in complex real-world scenarios.
  - **Unseen Accuracy**: Maintained at 65% (Â±3.18), indicating effective generalization capabilities.

### Ablation Study

- **Single Object Task with Different Features**:
  - **Using Only Similarity Scores**:
    - Seen: Improved from 88% (Â±3.24) baseline to 93% (Â±2.26) with our model.
    - Unseen: Slight improvement from 67% (Â±4.72) baseline to 68% (Â±3.15).
  - **Similarity Scores + Top1 Scores**:
    - Seen: 92% (Â±1.37) with our approach compared to 87% (Â±3.36) baseline.
    - Unseen: Our model's 78% (Â±3.79) closely follows the baseline's 79% (Â±4.01).
  - **All Features Combined**:
    - Our method achieved near parity with the baseline, with both scoring around 87% for unseen accuracy.

---

<!-- ## ğŸ–¼ï¸ Visualizations

- **Dataset Samples**: Showcase the variety and complexity of the dataset images, including icon-based and real-world scenarios.
- **Model Performance Charts**: Graphs depicting the accuracy and efficiency of the Perception and Reasoning Models under various conditions.
- **Comparative Analysis**: Visual comparisons between standard object detection models and the newly developed model, emphasizing improvements.

---
-->
